{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d70d8f-7047-4408-8cf4-f169f0703631",
   "metadata": {},
   "source": [
    "# Training Naive model - Patch-Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a3699-7cd7-400e-b8bf-27f0644768bf",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2c073-86f3-4299-88c4-b82e20ef8b65",
   "metadata": {},
   "source": [
    "In this notebook, we will train a naive model using the same structure as in **training_and_augmentation.ipynb**, but without data augmentation, oversampling, or focal loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24c739f0-36dd-42a0-a73a-67ab243b4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms    \n",
    "from torch.utils.data import random_split\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8decf100-e9fb-4ab0-ba06-5d0e643fcff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesser = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), #This normalization will be required by our model\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474259d7-cbf4-460d-92c6-7a9d2fa5468e",
   "metadata": {},
   "source": [
    "### 3.1 Data Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d97d8-563f-4839-a790-72f94c5e655b",
   "metadata": {},
   "source": [
    "We will start by dividing the expanded dataset into a training set and a test set. T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6469e26-46ba-45b1-94c0-3b933dadc8b5",
   "metadata": {},
   "source": [
    "We created the code below with a function that ensures the `split_dataset` folder does not accumulate repeated images by deleting all files inside it beforehand if the folder already exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8ba7456-39b8-40aa-9bbe-a948086b1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_data_path = \"../data/expanded_data\" #path to expanded data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1be7b7f-cde0-480c-9111-d7cb386db224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "output_dir = \"../data/split_dataset_naive_model\" #output directory\n",
    "\n",
    "test_size = 0.2 # we used a small size because we want to take advantage of all maximum amount of images\n",
    "random_state = 42\n",
    "\n",
    "def clear_and_create_dir(path): # function to clean the directory and avoid duplicate files\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)  \n",
    "    os.makedirs(path)      \n",
    "    \n",
    "for split in ['train', 'test']: \n",
    "    split_dir = os.path.join(output_dir, split)\n",
    "    clear_and_create_dir(split_dir)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label in os.listdir(expanded_data_path):\n",
    "    class_dir = os.path.join(expanded_data_path, label)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        if img_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            images.append(os.path.join(class_dir, img_name))\n",
    "            labels.append(label)\n",
    "\n",
    "train_imgs, test_imgs, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=test_size, stratify=labels, random_state=random_state\n",
    ")\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    split_dir = os.path.join(output_dir, split)\n",
    "    for label in set(labels):\n",
    "        os.makedirs(os.path.join(split_dir, label), exist_ok=True)\n",
    "\n",
    "def copy_images(img_list, label_list, split):\n",
    "    for img_path, label in zip(img_list, label_list):\n",
    "        dest_dir = os.path.join(output_dir, split, label)\n",
    "        shutil.copy(img_path, dest_dir)\n",
    "\n",
    "copy_images(train_imgs, train_labels, 'train')\n",
    "copy_images(test_imgs, test_labels, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9284f8-5005-44d9-a0a3-c0f57d2e452c",
   "metadata": {},
   "source": [
    "### 3.3 Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "985dcc79-125c-4e48-bb82-5eb95cc783be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torchvision\n",
    "train_path  = os.path.join(output_dir, \"train\")\n",
    "test_path  = os.path.join(output_dir, \"test\")\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=train_path, transform=preprocesser)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=test_path, transform=preprocesser)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d929892-f580-4fa4-9dee-adc788f32df9",
   "metadata": {},
   "source": [
    "## 5. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7e8145-25ba-4f8b-8c82-068ac8a5e1c0",
   "metadata": {},
   "source": [
    "### 5.1. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa43d08-0c08-488d-83b1-e7435ea1ffb1",
   "metadata": {},
   "source": [
    "We will use a pretrained model with a large number of parameters, utilizing its default weights in almost all the layers. This helps us because training such a large model from scratch on our device would be infeasible within a reasonable time. Moreover, we can leverage the patterns learned by the pretrained model and apply fine-tuning to adapt it specifically to our task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f887c-d347-41cd-aad4-b40f99ffd30e",
   "metadata": {},
   "source": [
    "The pretrained model we will use is **MobileNetV2_64**. We chose it because it is a lightweight model (allowing us to train some of its layers) while still being powerful enough for our task. This model requires input images of size (3, 224, 224). That’s why we configured the preprocessor as explained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0409b0bd-4135-4c03-aad3-28377b02cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "\n",
    "weights = MobileNet_V2_Weights.DEFAULT  \n",
    "model_mobilnet_v2 = mobilenet_v2(weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f8d4e-0ce8-40a6-b190-eb37d0110643",
   "metadata": {},
   "source": [
    "### 5.2. Fine Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ff1b6-2e6c-4be0-aa98-b8e260678c77",
   "metadata": {},
   "source": [
    "We freeeze every layer of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32e505b-2478-44f1-9cff-35e4839a1b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_mobilnet_v2.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f572199-ba53-45e1-8a5b-9c7175b0428c",
   "metadata": {},
   "source": [
    "Then, we set the last two important layers—a linear layer and a convolutional layer—to be trainable. Additionally, we need to modify the last linear layer to output a tensor with two values, since this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbf7dc01-0652-44e2-b6d5-f45afe208aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobilnet_v2.classifier[1] = nn.Linear(1280, 1)\n",
    "for param in model_mobilnet_v2.classifier[1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model_mobilnet_v2.features[18][0].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ba054-a084-4e2a-9349-daf7354ea19b",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb68ac5-2841-4edd-8a91-5b1df22780a1",
   "metadata": {},
   "source": [
    "### 6.1. Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb8e1c01-1121-4fb6-adbf-b4d1be12da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47fb3a-fc15-4fa8-8711-84a662955cbf",
   "metadata": {},
   "source": [
    "The optimizer should update only the trainable layers. We will use the Adam optimizer, a popular and effective choice for many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e8a6fe3-39b5-4c27-a4b5-030a9f433072",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = [p for p in model_mobilnet_v2.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5af1f6-8d06-4bb2-8167-ce6334569b67",
   "metadata": {},
   "source": [
    "### 6.2. Training iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1fdbb-d2e1-4e45-9b44-2b208fdf5675",
   "metadata": {},
   "source": [
    "We will avoid using automatic learning rate schedulers. This is because each epoch takes a long time to run on my device, so using a scheduler could prolong the training unnecessarily. Additionally, since our dataset is small, the loss will tend to decrease regardless, and overfitting is likely to occur quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c9e644a-fb6c-47d6-bb88-63b3f92d61e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 2/20\n",
      "Epoch 3/20\n",
      "Epoch 4/20\n",
      "Epoch 5/20\n",
      "Epoch 6/20\n",
      "Epoch 7/20\n",
      "Epoch 8/20\n",
      "Epoch 9/20\n",
      "Epoch 10/20\n",
      "Epoch 11/20\n",
      "Epoch 12/20\n",
      "Epoch 13/20\n",
      "Epoch 14/20\n",
      "Epoch 15/20\n",
      "Epoch 16/20\n",
      "Epoch 17/20\n",
      "Epoch 18/20\n",
      "Epoch 19/20\n",
      "Epoch 20/20\n",
      "The training lasted 1906.2442400455475 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 20\n",
    "losses = torch.zeros(num_epochs)\n",
    "\n",
    "model_mobilnet_v2.train()  \n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    counter = 0\n",
    "    current_loss = 0.0\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad() \n",
    "        y = y.unsqueeze(1).float()\n",
    "        outputs = model_mobilnet_v2(X)\n",
    "        l = criterion(outputs, y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        counter += 1\n",
    "        current_loss += l.item()  \n",
    "\n",
    "    losses[epoch] = current_loss / counter\n",
    "\n",
    "end = time.time()\n",
    "print(f'The training lasted {end - start} seconds.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19593060-f6bb-4f06-9c86-e8af590d4498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b4025-1a78-4702-9a3a-cba5ccc1ad10",
   "metadata": {},
   "source": [
    "As we can see, the loss decreased steadily throughout training until the last 5 epochs, where it got stuck. This is a symptom of reaching a minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9a68b4-17b7-40e9-95a3-fa4e9bf3af8d",
   "metadata": {},
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef93d70-bbc8-4307-8121-ee5f630ad35a",
   "metadata": {},
   "source": [
    "### 7.1. Classification on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87b2be0-6fa5-4adb-aa18-508e35d2023f",
   "metadata": {},
   "source": [
    "To classify the samples in the test set, we will use a threshold t. If the predicted probability of belonging to the positive class exceeds $t$, we classify the sample as positive. Since our model will likely struggle to detect Waldo due to the scarcity of positive samples, we will set the threshold to $t = 0.5$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ebd7a60-c358-434f-a17f-18998e06cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e5b8f48-1d22-4b08-8e77-02e7d770763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobilnet_v2.eval() # We set the model to evaluation mode because now we want to predict, not train.\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "test_losses = torch.zeros(num_epochs)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    counter = 0\n",
    "    for X, y in test_loader:\n",
    "        counter = 0\n",
    "        outputs = model_mobilnet_v2(X)\n",
    "        probs = torch.sigmoid(outputs) # We need to apply sigmoid to convert logits into probabilities.\n",
    "        preds = (probs > threshold).int()\n",
    "        \n",
    "        all_preds.extend(preds.squeeze(1).cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20935d-1ab9-4dde-ad03-974ed0331a22",
   "metadata": {},
   "source": [
    "### 7.2. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08dc2526-1078-4eab-9ec9-d5f8b04b761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c76caf6-15cc-42fc-8209-4974d8649f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4329608938547486\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4467fb73-137c-4ecf-bf78-4da834fc6069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4329608938547486\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(all_labels, all_preds, average='weighted')  \n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "490e81f3-bb14-411f-a53d-cb799b82bd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333]\n"
     ]
    }
   ],
   "source": [
    "class_1_recall = recall_score(all_labels, all_preds, labels=[1], average=None)\n",
    "print(class_1_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec2029dc-c731-4833-bbcb-f4ac44ae2e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4335206]\n"
     ]
    }
   ],
   "source": [
    "class_0_recall = recall_score(all_labels, all_preds, labels=[0], average=None)\n",
    "print(class_0_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e28fa736-130a-40d1-ac9a-a40b4bbb6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_mobilnet_v2.state_dict(), \"../model/waldo_detector_64x64_v1.0.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092cf62-51a9-4209-a4d6-f10c9f8bda50",
   "metadata": {},
   "source": [
    "As we can see, the metrics in this case are quite poor. The loss is close to 0 because the model has learned to always predict class 1, which corresponds to \"not Waldo\" in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf4da8-6ade-4bc0-87b5-fee71170aab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
